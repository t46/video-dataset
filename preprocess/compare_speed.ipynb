{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/videos/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from streaming import StreamingDataset\n",
    "import time\n",
    "from tqdm import tqdm   \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streaming\n",
    "streaming.base.util.clean_stale_shared_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote directory (S3 or local filesystem) where dataset is stored\n",
    "remote_dir = '/root/projects/rl-nlp/videos/data_downsampled/mds/00000'\n",
    "\n",
    "# Local directory where dataset is cached during operation\n",
    "local_dir = '/root/projects/rl-nlp/videos/cache/split'\n",
    "dataset = StreamingDataset(local=local_dir, remote=remote_dir, split=None, shuffle=False)\n",
    "\n",
    "# Create PyTorch DataLoader\n",
    "dataloader_split = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/247 [00:00<?, ?it/s]/root/miniconda3/envs/videos/lib/python3.11/site-packages/streaming/base/dataset.py:722: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
      "  shard_shuffle_units = [shard_samples] * (shard_choose // shard_samples)\n",
      "/root/miniconda3/envs/videos/lib/python3.11/site-packages/streaming/base/dataset.py:723: RuntimeWarning: divide by zero encountered in scalar remainder\n",
      "  remainder = shard_choose % shard_samples\n",
      "/root/miniconda3/envs/videos/lib/python3.11/site-packages/streaming/base/dataset.py:730: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
      "  num_full_repeats = shard_choose // shard_samples\n",
      "/root/miniconda3/envs/videos/lib/python3.11/site-packages/streaming/base/dataset.py:738: RuntimeWarning: divide by zero encountered in scalar remainder\n",
      "  shortfall = shard_choose % shard_samples\n",
      "/root/miniconda3/envs/videos/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:171: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "  0%|          | 0/247 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.483183860778809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i, data in enumerate(tqdm(dataloader_split)):\n",
    "    break\n",
    "end = time.time() - start\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 333, 1, 360, 640, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = data['frame']\n",
    "subtitle = data['subtitle']\n",
    "batch_size = frame.shape[0]\n",
    "num_frames = frame.shape[1]\n",
    "num_chunks = frame.shape[2]\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 333, 1, 40])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'every family has their good seeds and\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle[0, 0, 0, :].numpy().tobytes().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote directory (S3 or local filesystem) where dataset is stored\n",
    "remote_dir = '/root/projects/rl-nlp/videos/data_downsampled/mds-not-split/00000'\n",
    "\n",
    "# Local directory where dataset is cached during operation\n",
    "local_dir = '/root/projects/rl-nlp/videos/cache/not-split'\n",
    "dataset = StreamingDataset(local=local_dir, remote=remote_dir, split=None, shuffle=False)\n",
    "\n",
    "# Create PyTorch DataLoader\n",
    "dataloader_not_split = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/247 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.124604940414429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "chunked_frames = []\n",
    "chunked_subtitle = []\n",
    "chunk_unit = 1\n",
    "for i, data in enumerate(tqdm(dataloader_not_split)):\n",
    "    # NOTE: If you wanna do just a equal splitting, just do torch.chunk(data['frame'], num_chunked_frames, dim=1)\n",
    "    chunk_start_pos = 0\n",
    "    for j in range(data['frame'].shape[1]):\n",
    "        if (j > 0) and (subtitle != data['subtitle'][0, j, :].numpy().tobytes().decode('utf-8')):\n",
    "            num_chunks = (j - chunk_start_pos) // chunk_unit\n",
    "            chunked_frames += torch.chunk(data['frame'][0, chunk_start_pos:j, :, :, :], num_chunks, dim=1)\n",
    "            chunked_subtitle += torch.chunk(data['subtitle'][0, chunk_start_pos:j, :], num_chunks, dim=1)\n",
    "            chunk_start_pos = j\n",
    "        subtitle = data['subtitle'][0, j, :].numpy().tobytes().decode('utf-8')\n",
    "    break\n",
    "end = time.time() - start\n",
    "print(end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
