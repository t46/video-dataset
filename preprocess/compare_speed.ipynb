{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/videos/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from streaming import StreamingDataset\n",
    "import time\n",
    "from tqdm import tqdm   \n",
    "import torch\n",
    "import streaming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming.base.util.clean_stale_shared_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote directory (S3 or local filesystem) where dataset is stored\n",
    "remote_dir = '/root/projects/rl-nlp/videos/data_downsampled/mds-split/00000'\n",
    "\n",
    "# Local directory where dataset is cached during operation\n",
    "local_dir = '/root/projects/rl-nlp/videos/cache/split'\n",
    "dataset = StreamingDataset(local=local_dir, remote=remote_dir, split=None, shuffle=False)\n",
    "\n",
    "# Create PyTorch DataLoader\n",
    "dataloader_split = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.022639989852905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i, data in enumerate(tqdm(dataloader_split)):\n",
    "    break\n",
    "end = time.time() - start\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 140, 5, 360, 640, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = data['frame']\n",
    "subtitle = data['subtitle']\n",
    "batch_size = frame.shape[0]\n",
    "num_frames = frame.shape[1]\n",
    "num_chunks = frame.shape[2]\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 140, 5, 40])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming.base.util.clean_stale_shared_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote directory (S3 or local filesystem) where dataset is stored\n",
    "remote_dir = '/root/projects/rl-nlp/videos/data_downsampled/mds-not-split/00000'\n",
    "\n",
    "# Local directory where dataset is cached during operation\n",
    "local_dir = '/root/projects/rl-nlp/videos/cache/not-split'\n",
    "dataset = StreamingDataset(local=local_dir, remote=remote_dir, split=None, shuffle=False)\n",
    "\n",
    "# Create PyTorch DataLoader\n",
    "dataloader_not_split = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6408374309539795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "chunked_frames = []\n",
    "chunked_subtitle = []\n",
    "chunk_unit = 5\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader_not_split)):\n",
    "    num_chunks, remainder = divmod(data['frame'].shape[1], chunk_unit)\n",
    "    chunked_frame = torch.chunk(data['frame'][:, :-remainder, :, :, :], num_chunks, dim=1)\n",
    "    chunked_subtitle = torch.chunk(data['subtitle'][:, :-remainder, :], num_chunks, dim=1)\n",
    "    break\n",
    "end = time.time() - start\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 703, 360, 640, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['frame'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
